{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7568a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "import os\n",
    "\n",
    "access_key = os.getenv('aws_access_key')\n",
    "secret_key = os.getenv('aws_secret_key')\n",
    "\n",
    "# Create a Spark session\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Raw ETL\")\n",
    "    .config('spark.jars.packages', 'io.openlineage:openlineage-spark:0.3.+,org.apache.hadoop:hadoop-aws:3.2.0')\n",
    "    .config('spark.extraListeners', 'io.openlineage.spark.agent.OpenLineageSparkListener')\n",
    "    .config('spark.openlineage.host', 'http://marquez-api:5000')\n",
    "    .config('spark.openlineage.namespace', 'spark_integration')\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key)\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key)\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d554d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data and write to bucket\n",
    "data = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"s3a://landing-zone/deniro.csv\")\n",
    "transformed = data.withColumn(\"Actor\", lit(\"Robert De Niro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.write\\\n",
    "           .format('csv')\\\n",
    "           .option('header','true')\\\n",
    "           .save('s3a://raw/raw_data.csv',mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock data and write to bucket\n",
    "mock = [(1980,10), \n",
    "        (1984,20), \n",
    "        (1988,30), \n",
    "        (1992,40),\n",
    "        (1996,50) \n",
    "      ]\n",
    "mockColumns = [\"Year\",\"Val\"]\n",
    "mockDF = spark.createDataFrame(data=mock, schema = mockColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mockDF.write.format('csv')\\\n",
    "      .option('header','true')\\\n",
    "      .save('s3a://raw/extra_data.csv', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c75dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
